# 11. Training Neural Networks (Part 2)

**`강의 영상`**                      

https://www.youtube.com/watch?v=qcSEP17uKKY&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r&index=11

**`강의 자료`**

https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture11.pdf

___

# Training dynamics

아래에서 배울 내용들은 **Training 중에 시도할 수 있는 방법**들이다.

# Learning Rate Scheduling

예전 강의에서 **SGD, SGD + Momentum, Adagrad, RMSProp, Adam** 등, **어떠한 `Optimizer`이던지 상관없이 모든 `Optimizer`는 `Learning rate`를 `Hyperparameter`로 갖는다.**

`Learning rate`는 Deep Learning model의 `Hyperparameter` 중 가장 중요한 `Hyperparameter` 중 하나이다.

![alt text](image-376.png)

- `Learning rate`가 너무 작은 경우, `Training`에 너무 **오랜 시간이 소요**된다.

- `Learning rate`가 너무 큰 경우, 최솟값을 지나칠 가능성이 있다.

따라서 가장 중요한 것은 **너무 크지도, 너무 작지도 않은 적당한 값의 `Learning rate`를 사용**하는 것이 중요하다. 

그럼 적당한 값의 `Learning rate`를 어떻게 찾을 수 있을까?

- 일반적으로 사용하는 방법은 **큰 `Learning rate`부터 시작해서 `Training`을 해보며 `Learning rate`를 조금씩 줄여나가는 것**이다.

- `Learning rate`를 바꾸어가며 **가장 좋은 성능을 내는 `Learning rate`를 선택**하기 때문에 `Learning rate scheduling`이라고 부른다.

### Learning Rate Decay: Step 

> **가장 많이 사용되는 Learning rate scheduling 방법 중 하나**

특정 `Epoch`마다 `Learning rate`를 **일정한 비율로 줄이거나 일정한 값만큼 감소**시키는 방법

![alt text](image-377.png)

`ResNet`에서 이 방법을 사용하였다.

- `RestNet`에서는 `Epoch`: 30, 60, 90마다 `Learning rate`를 10배씩 감소하는 방법을 이용하였다.

- 학습 초기에 `Learning rate`가 커서 **학습 초기에 빠르게 `Minimum`에 도달**할 수 있는 빠른 학습이 가능하다.

- 학습 후반에는 `Learning rate`가 작아서 **세밀하게 `Minimum`을 탐색**할 수 있다.

- 일반적으로도 **`Learning rate`를 학습 초기에 크게, 학습 후반에 작게 설정하는게 유리**하다.

하지만, 이 방법은 Model에 **너무 많은 `Hyperparameter`가 도입된다는 단점이 존재**한다.

- **어떤 `Epoch`마다 어떤 비율이나 크기만큼 `Learning rate`를 줄여야 할 지**에 대한 `Hyperparameter`가 요구된다.

- 모델에 `Hyperparameter`가 늘어날수록 **설계자가 투자해야하는 시간이 늘어나고**, **많은 `Trial and Error`를** 겪어야 한다.

### Learning Rate Decay: Cosine

전체 학습 `Epoch`에서의 `Learning rate`가 **Cosine 함수의 반주기**에 해당되도록 설정하는 방법

![alt text](image-378.png)
- $T$: Total Epoch, $\alpha_0$: Initial Learning rate, $t$: 현재 시점의 Epoch

이 방법을 사용하게 되면 **학습 초기에 `Initial learning rate`를 사용하고 전체 Epoch 후에는 `Learning rate`로 0을 갖도록 할 수 있다.**

이 방법을 `Learning rate`로 사용하게 되면, **추가적인 `Hyperparameter`가 필요없다**는 장점이 있다.

- **Cosine**을 사용했을 때, 요구되는 `Hyperparameter`는 **Total Epoch와 Initial Learning rate**인데, 이는 어느 `Learning rate`를 사용하던 Deep Learning Model을 설계할 때 항상 요구된다.

### Learning Rate Decay: Linear

![alt text](image-379.png)

**Cosine**처럼 **`Initial Learning rate`에서 시작하여 점점 감소하는 형태**를 갖는다.

**Cosine**과 **Linear**간의 성능은 거의 비슷하다.

- 대부분의 연구자들은 **각 분야의 선행 연구에서 어떤 방법을 사용했는지를 그대로 따른다.**

- 분야에 따라 각 방법이 뛰어난 경우가 있다.

### Learning Rate Decay: Inverse Sqrt

![alt text](image-380.png)

**Cosine, Linear**처럼 **`Initial Learning rate`에서 시작하여 점점 감소하는 형태**를 갖는다.

그러나 이 방법은 **Cosine, Linear**에 비해 **큰 `Learning rate`를 사용하는 구간이 비교적 짧은 것**을 확인할 수 있다.


### Learning Rate Decay: Constant

전체 `Epoch` 내내 동일한 `Learning rate`를 사용하는 방법이다.

![alt text](image-381.png)

Deep Learning Model을 구축하고 프로세스 초기에 사용하기 좋다.

- 다른 `Learning Rate Decay`를 이용하는 것은 **프로세스가 어느 정도 진행된 이후에 시도하는 편**이 낮다.

- **성능을 챙기는 것보다 빠르게 모델을 실행하고, 적용**해야할 때 유용하다.

### Addition

`Momentum + SGD`를 이용하는 경우에는 `Learning rate`가 감소하는 형태인 방법을 사용하는 것이 좋다.


하지만, `Adam`이나 `RMSProp`과 같이 복잡한 `Optimizer`를 사용하는 경우에는 `Constant`를 사용하는게 좋다.

### How long to train?

`Early Stopping`을 사용할 수 있다.

![alt text](image-382.png)

`Neural Network`를 `Training`할 때에는 **`Validation Accuracy`가 가장 높은 지점에서 꺾이기 시작할 때, `Training`** 을 중지시켜야 한다.

- 이를 위해, `Training` 과정에서 특정 `Epoch`마다 `Loss`와 `Accuracy`를 저장해 위 예시처럼 그래프로 시각화할 수 있어야 한다.

# Choosing Hyperparameter

## Grid Search

> **가장 흔하게 시도하는 방법**

`Hyperparameter`로 사용하고 하는 값을 **`Hyperparameter` 집합**으로 만들고, **그 값을 모두 이용하여 테스트해보고 가장 성능이 좋은 것을 선택하는 방법**

![alt text](image-383.png)

- 보통 한 집합 내에서 `Hyperparameter`값들은 `Log`를 취했을 때, `Linear`하도록 설정한다.

하지만, 모든 가능한 `Hyperparameter` 집합에 대해 전부 테스트 해야하기 때문에 **`GPU`가 충분한 경우에만 사용할 수 있는 방법**이다.


## Random Search

> **Grid Search가 요구하는 GPU 성능이 부담되는 경우에 주로 사용하는 방법**

`Hyperparameter` 집합을 설정하는 것이 아니라, `Hyperparameter`의 **가능한 범위**만을 지정해주면 **`Training` 시마다 범위내에서 `Random`한 값을 사용하는 방법**이다.

![alt text](image-384.png)

여전히 꽤 많은 `GPU`의 사용이 필요하지만, `Grid Search`에 비해 비교적 낫다.

### Example

보라색 부분이 성능이 좋은 부분이다.

![alt text](image-386.png)

- 붉은색 선 부분은 **가장 성능이 좋은 `Hyperparameter`를 의미한다.**

## Grid vs Random

> **Random Search 방법이 Grid Search에 비해 더 적은 시도를 통해 더 좋은 성능을 내고, GPU도 비교적 적게 사용할 수 있는 이유를 알아보자.**

아래 예시는 두 `Hyperparameter`가 존재할 때, 한 `Hyperparameter`는 성능에 중요한 영향을 미치고, 다른 `Hyperparameter`는 큰 영향을 미치지 않는 경우이다.

![alt text](image-385.png)

위 같은 경우에, `Grid Search`는 각 `Hyperparameter`에 대해 9번의 `Training`에도 불구하고, **3개의 Sample만**을 얻을 수 있게 된다.

- 이것은 여러번의 시도에도 불구하고, **특정 `Hyperparameter`의 성능 분포를 비교적 정확하게 알 수 없을 가능성이 크다**는 것을 의미한다.

- 중요하다고 생각되는 `Hyperparameter` 집합의 크기를 늘리면 해결되지만, **`Training` 전에 어떤 `Hyperparameter`가 중요할 지 알 수 없다는 것이 문제**가 된다.

반면, `Random Search`는 9번의 `Training`에 **특정 `Hyperparameter`의 성능 분포에 대해 9개의 Sample**을 얻을 수 있다.

- 이는 `Hyperparameter`의 성능 분포를 **비교적 정확**하게 알 수 있다는 것을 의미한다.

추가로, `Random Search`는 범위 내에서 특정 값을 갖도록 강제하는 것이 아니라 **랜덤하게 샘플링**하기 **정확히 최고의 성능**을 갖도록 하는 `Hyperparameter`를 정확하게 나타낼 수도 있다.

- 사전에 어떤 `Hyperparameter`가 중요한지 몰라도, 랜덤하게 찾기 때문에 **최고의 성능을 가지는 하이퍼파라미터 조합에 더 쉽게 도달**할 수 있다.

____

이 아래부터는 많은 양의 `GPU` 사용 없이, `Hyperparameter`를 선택하는 방법을 알아보자.

### 1. Initial Loss Check

우선 모델을 구현하고, 가장 먼저 해야하는 일은 `Initial Loss`를 확인하는 것이다.

- 이전에 `Hinge loss`와 `Cross Entropy Loss` 두 가지 `Loss function`을 배울 때, 배웠던 것처럼 **사용하는 `Loss function`의 종류에 따라, `Training`을 진행하지 않았을 때 근사치로 나와야하는 값이 존재한다.**

![alt text](image-387.png)

- `Weight Update`를 끄고, 한번 실행하여 `Loss` 값이 무엇인지 확인한다.

### 2. Overfit a small sample (5 ~ 10 Batch)

다음으로 할 작업은 **매우 작은 5 ~ 10개의 Sample로 이루어진 Batch**에 대해 **모델이 거의 100%의 정확도를 가질 수 있도록 `Overfit`하는 것**이다.

![alt text](image-388.png)
정하고 
- **Architecture의 Layer, size / Learning rate, Weight Initialize를 조절하여 100%에 가까운 정확도를 얻을 수 있어야 한다.**
  
- 이 단계에서 **낮은 정확도**를 얻는다면, 전체 Training Dataset에 대해 **높은 정확도를 얻을 가능성은 거의 없다.**

- 이 단계에서 **낮은 정확도를** 얻는다면, **최적화 과정에서의 버그** 등을 의심해보아야 한다. 

중요한 점은 Data에 대해 `Overfit` 시켜야하기 때문에, **`Regulraization` = `Weight Decay`를 꺼야한다는 점**이다.

### 3. Find Learning Rate that makes loss go down

이 단계부터 전체 `Training Dataset`을 사용한다.

두 번째 단계에서 **사용한 모델 전체**를 그대로 불러와서, 전체 `Training Dataset`에 대해 적용한다.

![alt text](image-389.png)

- 이 단계에서의 목표는 **`Learning rate`와 `Weight Decay`를 조정**하여, **처음 100번의 Iteration 내에 `Loss`를 크게 줄여 수렴**시키는 것이다.

- 처음 100번 내에 줄여야하는 이유는 경험적으로 **`Loss`가 초반 `Iteration`에 `Exponential` 하게 감소하는 경향**이 있기 때문이다.

### 4. Coarse grid, Train for ~1-5 epochs

세 번째 단계에서 얻은 모델이 **가장 좋은 성능을 보이는 `Learning rate`와 `Weight Decay` 근처에서 아주 작은 `Grid`를 사용**하여 **1 ~ 10회 사이의 적은 `Epoch`로 `Grid Search`를** 해본다.

![alt text](image-390.png)

### 5. Refine grid, Train longer

네 번째 단계에서의 결과를 보고, **`Grid`를 세밀하게 조정**하여 **네 번째 단계보다 길게 학습**시킨다.

![alt text](image-391.png)

### 6. Look at Learning Curve

다섯 번째 단계의 결과를 이용하여 `Learning Curve`를 얻고, 분석하여 더 세밀하게 모델을 조정한다.

### 7. GOTO step 5

여섯 번째 단계의 결과를 분석하여, `Hyperparameter`를 조정하여 **다섯 번째 단계부터 다시 진행**한다.

____

`Learning Curve`에 대해 자세히 알아보자

일반적인 `Learning Curve`는 아래와 같이 이루어진다.

![alt text](image-392.png)

- `Loss`의 경우 `Nosiy`하기 때문에 평균선으로 나타내는 경우가 많다.


`Learning Curve`를 분석하는 방법을 살펴보자.

### 1. `Loss Curve`가 초반에 평평하다가 갑자기 급격히 감소지는 경우

**초반에 학습이 제대로 이루어지지 않은 것**을 의미하기에, **`Weight Initialize`가 잘못되었을 가능성이** 크다.

![alt text](image-393.png)

### 2. 초반에 `Loss`가 갑소하다가 점점 학습이 이루어지지 않는 경우

**`Learning rate`가 커서 중후반에 학습이 제대로 이루어지지 않았을 가능성이 크기 때문에 `Learning rate decay`를 시도해야 한다.**

![alt text](image-394.png)

`Learning rate decay`를 너무 이른 시간에 시도하면 아래와 같이 학습이 중단될 수 있다.

![alt text](image-395.png)

- 그래프를 보면, 학습이 정체되기 직전에 **크게 감소하는 구간**이 보인다.

- **`Learning rate`를 그대로 놔뒀으면 학습이 제대로 이루어졌을텐데,** `Learning rate`가 감소되어 학습이 제대로 이루어지지 않은 것을 의미한다.

### 3. `Train Accuracy`와 `Validation Accuracy`가 계속 증가하는 경우

**`Accuracy`가 감소하지 않았다는 것**은 더 `Training`하면 Accuracy가 늘어날 수도 있기 때문에 **`Training`을 더 길게 진행**해야 한다.**


### 4. `Train Accuracy`와 `Validation Accuracy`간의 차이가 많이 나는 경우

`Train Accuaracy`가 `Validation Accuarcy`보다 큰 경우, `Overfitting`을 의미하기 때문에, **`Regularization`을 적용해야 한다.**

![alt text](image-396.png)

### 5. `Train Accuracy`와 `Validation Accuracy`간의 차이가 나지 않는 경우

`Train Accuaracy`와 `Validation Accuarcy` 차이가 나지 않는 경우, `Underfitting`을 의미하기 때문에, **모델의 크기를 늘리거나 `Regularization`을 줄여야 한다.**

![alt text](image-397.png)

- 경험적으로, 이미 본 `Training Data`와 본 적이 없는 `Validation Data` 간에는 **어쩔 수 없는 차이가 존재**하기 때문이다.

## Addition

우리가 `Deep Learning Model`을 설계하면서 다룰 수 있는 `Hyperparameter`는 대표적으로 아래와 같다.

![alt text](image-398.png)

다른 효율적인 방법은 `Cross Validation`을 이용하는 방법도 있다.

`Hyperparameter`를 설정하고 `Training`할 때, 내가 **설정한 `Hyperparameter`가 잘못되었는 지 확인할 수 있는 방법**도 있다.

이 중 한가지는 `Ratio of Weight Update`와 `Weight Magnitude`를 살펴보는 것이다.

일반적으로 **`Weight`를 업데이트하기 전의 `Weight` 값 자체와 `Weight`가 업데이트되는 비율**간의 **비율**은 너무 크면 좋지 않다.

- `Update할 Weight 값` / `Update할 Weight의 비율`

- **0.001과 유사한 값을 갖는 것이 좋다**고 한다.

- 이를 디버깅 방법 중 하나로 사용할 수 있다.
  

![alt text](image-399.png)

- 이를 통해, `Learning rate`, `Weight Initialize`가 적절한 지 확인할 수 있다.

# After Training